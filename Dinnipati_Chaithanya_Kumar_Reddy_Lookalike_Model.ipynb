{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyPEz8uKXSFiMjH7WI12pouI",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/dchaithanya123/ZeoTap/blob/main/Dinnipati_Chaithanya_Kumar_Reddy_Lookalike_Model.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Z0Z6NK4KYQc3",
        "outputId": "3d27afd7-f8a7-4406-e814-45a4b3589182"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Customers Dataset Columns: Index(['CustomerID', 'CustomerName', 'Region', 'SignupDate'], dtype='object')\n",
            "Products Dataset Columns: Index(['ProductID', 'ProductName', 'Category', 'Price'], dtype='object')\n",
            "Available Customer IDs: ['C0001' 'C0002' 'C0003' 'C0004' 'C0005' 'C0006' 'C0007' 'C0008' 'C0009'\n",
            " 'C0010' 'C0011' 'C0012' 'C0013' 'C0014' 'C0015' 'C0016' 'C0017' 'C0018'\n",
            " 'C0019' 'C0020']\n",
            "  CustomerID                                         Lookalikes\n",
            "0      C0001  [(C0099, 1.0000000000000002), (C0091, 1.000000...\n",
            "1      C0002  [(C0005, 1.0000000000000002), (C0084, 1.000000...\n",
            "2      C0003  [(C0099, 1.0000000000000002), (C0091, 1.000000...\n",
            "3      C0004  [(C0099, 1.0000000000000002), (C0091, 1.000000...\n",
            "4      C0005  [(C0005, 1.0000000000000002), (C0084, 1.000000...\n"
          ]
        }
      ],
      "source": [
        "import pandas as pd\n",
        "from sklearn.metrics.pairwise import cosine_similarity\n",
        "from sklearn.preprocessing import StandardScaler, OneHotEncoder\n",
        "from sklearn.compose import ColumnTransformer\n",
        "from sklearn.pipeline import Pipeline\n",
        "import numpy as np\n",
        "\n",
        "# Load datasets\n",
        "customers = pd.read_csv('/content/Customers.csv')\n",
        "products = pd.read_csv('/content/Products.csv')\n",
        "\n",
        "# Clean up column names by stripping leading/trailing spaces\n",
        "customers.columns = customers.columns.str.strip()\n",
        "products.columns = products.columns.str.strip()\n",
        "\n",
        "\n",
        "# Inspect the column names of datasets\n",
        "print(\"Customers Dataset Columns:\", customers.columns)\n",
        "print(\"Products Dataset Columns:\", products.columns)\n",
        "\n",
        "\n",
        "# Ensure the necessary columns exist\n",
        "if 'CustomerID' not in customers.columns:\n",
        "    raise ValueError(\"'CustomerID' column is missing in the customers dataset.\")\n",
        "if 'ProductID' not in products.columns:\n",
        "    raise ValueError(\"'ProductID' column is missing in the products dataset.\")\n",
        "\n",
        "# Feature Engineering: Select relevant features for recommendation\n",
        "# We'll assume customers have data like Region, and products have data like Category and Price.\n",
        "# In a real scenario, we'd link customers and products based on their interactions, but here we'll treat them as separate features.\n",
        "\n",
        "# We'll merge customer information with some product categories for the recommendation\n",
        "merged_data = pd.merge(customers, products, how='cross')  # Cartesian join to combine customer profiles with all products\n",
        "\n",
        "# Now, we can create a set of features for the recommendation system:\n",
        "categorical_features = ['Region', 'Category']  # 'Region' from customers and 'Category' from products\n",
        "numerical_features = ['Price']  # 'Price' from products\n",
        "\n",
        "# Preprocessing pipeline\n",
        "preprocessor = ColumnTransformer([\n",
        "    ('num', StandardScaler(), numerical_features),\n",
        "    ('cat', OneHotEncoder(), categorical_features)\n",
        "])\n",
        "\n",
        "# Apply preprocessing to the dataset\n",
        "pipeline = Pipeline(steps=[('preprocessor', preprocessor)])\n",
        "data_transformed = pipeline.fit_transform(merged_data)\n",
        "\n",
        "# Compute similarity matrix\n",
        "similarity_matrix = cosine_similarity(data_transformed)\n",
        "\n",
        "# Check available customer IDs in the dataset\n",
        "available_customer_ids = customers['CustomerID'].values\n",
        "print(\"Available Customer IDs:\", available_customer_ids[:20])  # Display first 20 for inspection\n",
        "\n",
        "# Function to recommend top N similar customers for each customer\n",
        "def recommend_similar(customers_data, customer_id, top_n=3):\n",
        "    # Ensure customer_id exists in the dataset\n",
        "    if customer_id not in customers_data['CustomerID'].values:\n",
        "        raise ValueError(f\"CustomerID {customer_id} not found in the dataset.\")\n",
        "\n",
        "    # Find the index of the customer_id in the customers dataset\n",
        "    customer_index = customers_data[customers_data['CustomerID'] == customer_id].index[0]\n",
        "\n",
        "    # Get the indices of the corresponding rows in the merged_data (cross join results)\n",
        "    customer_rows = merged_data[merged_data['CustomerID'] == customer_id].index.tolist()\n",
        "\n",
        "    # Calculate similarity scores for each row corresponding to the customer\n",
        "    similarity_scores = similarity_matrix[customer_rows[0]]  # Start with the first row of the customer\n",
        "\n",
        "    # Get the top N most similar customers (excluding the customer itself)\n",
        "    similar_customers = np.argsort(similarity_scores)[::-1][1:top_n + 1]\n",
        "\n",
        "    recommendations = [\n",
        "        {\n",
        "            'CustomerID': merged_data.iloc[i]['CustomerID'],\n",
        "            'SimilarityScore': similarity_scores[i]\n",
        "        }\n",
        "        for i in similar_customers\n",
        "    ]\n",
        "\n",
        "    return recommendations\n",
        "\n",
        "# Generate recommendations for the first 20 customers\n",
        "lookalikes = {}\n",
        "for i in range(1, 21):  # For CustomerID C0001 to C0020\n",
        "    customer_id = f'C{i:04d}'\n",
        "    try:\n",
        "        recommendations = recommend_similar(customers, customer_id, top_n=3)\n",
        "        lookalikes[customer_id] = [(rec['CustomerID'], rec['SimilarityScore']) for rec in recommendations]\n",
        "    except ValueError as e:\n",
        "        print(e)\n",
        "\n",
        "# Convert the lookalike results into a DataFrame for export\n",
        "lookalike_df = pd.DataFrame([\n",
        "    {'CustomerID': customer_id, 'Lookalikes': lookalikes[customer_id]}\n",
        "    for customer_id in lookalikes\n",
        "])\n",
        "\n",
        "# Save the lookalike results to a CSV file\n",
        "lookalike_df.to_csv('Lookalike.csv', index=False)\n",
        "\n",
        "# Output some results\n",
        "print(lookalike_df.head())\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "W7pDWHBZbqsH"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}